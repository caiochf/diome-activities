# -*- coding: utf-8 -*-
"""Itens recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12sinOxFVAU8DgAgdPX2saGshr91kFu8c

Psalm (73:28)

"*But it is good for me to draw near to God: I have put my trust in the Lord GOD, that I may declare all thy works.*"

# References



*   **Dataset:** [Aggarwal, P. (2022) Fashion Product Images (Small)](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset)
*   **Inspiration**: [This notebook](https://colab.research.google.com/github/sparsh-ai/rec-tutorials/blob/master/_notebooks/2021-04-27-image-similarity-recommendations.ipynb#scrollTo=Q72U45CZtzAZ)

# Introduction

This notebook aims to simulate a simple recommendation system based on Deep Learning. Here VGG 16 (transfer learning) was used as feature extractor.

After training our model, we use the features from a Dense layer to calculate the correlation between the new item's features (supposing our client is buying something that wasn't in our original dataset). Finally, there is a function to recommend 3 itens most related to that item.

There are 4 examples at the end.

---

# Set up
"""

import torch

torch.cuda.is_available()

!pip install -q -U kaggle
!pip install --upgrade --force-reinstall --no-deps kaggle

!kaggle datasets download -d paramaggarwal/fashion-product-images-small
!unzip fashion-product-images-small.zip

import tensorflow as tf
import pandas as pd
import os, shutil, cv2

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

"""---

# Checking our data
"""

data = pd.read_csv("/content/myntradataset/styles.csv", on_bad_lines='skip')
data.head(10)

data.dtypes

data['id'] = data['id'].astype('str')
data['masterCategory'] = data['masterCategory'].astype('category')

data['masterCategory'].value_counts()

"""## Data reduction

Here we performed a reduction since there is plenty of data available but a few opportunities with free Colab, so...
"""

data = data.loc[data['masterCategory'].isin(['Apparel', 'Accessories', 'Footwear', 'Personal Care'])]
data = data.groupby('masterCategory').head(5001).reset_index(drop=True)

data['masterCategory'].value_counts()

"""## Selecting our examples

Here we take one of each 'masterCategory' item out. We don't want it to be seen during training (suppose they are new products added to the store).

They will be used as examples at the end of this notebook
"""

accessories_example = data[data['masterCategory'] == 'Accessories'].iloc[0]
index_1 = data[data['masterCategory'] == 'Accessories'].index[0]

appareal_example = data[data['masterCategory'] == 'Apparel'].iloc[0]
index_2 = data[data['masterCategory'] == 'Apparel'].index[0]

footwear_example = data[data['masterCategory'] == 'Footwear'].iloc[0]
index_3 = data[data['masterCategory'] == 'Footwear'].index[0]

personalcare_example = data[data['masterCategory'] == 'Personal Care'].iloc[0]
index_4 = data[data['masterCategory'] == 'Personal Care'].index[0]

rmv_indexes = [index_1, index_2, index_3, index_4]

data_train = data.drop(rmv_indexes)

data_train['masterCategory'].value_counts()

data_train['id'] = '/content/myntradataset/images/' + data_train['id'] + '.jpg' # to make our search for the images easier

"""---

# Creating our training and validation datasets
"""

import sklearn
from sklearn.model_selection import train_test_split

X, y = data_train['id'], data_train['masterCategory']
label_mapping, unique_labels = pd.factorize(y) #to use numbers instead of strings

X_train, X_valid, y_train, y_valid = train_test_split(X,label_mapping,
                                                    test_size = 0.2,
                                                    random_state = 7,
                                                    shuffle = True,
                                                    stratify = label_mapping)

"""The following functions will work as follows:



*   "**image_generator**": since our 'data_train' has not images but paths to images ('id' column) here we must access the paths and load those images as arrays to be used on the following function. Resizing and normalization were also included as we need them for padronization and better performace, respectly, for our model.

*   "**create_dataset**": now that we have the images matrices and their respective labels, we use this function to create our dataset with tensors and to batch it.
"""

IMG_SIZE = (64, 64)
BATCH_SIZE = 32

def image_generator(paths, labels):
    for path, label in zip(paths, labels):
        img = cv2.imread(path)
        if img is not None:
            img = cv2.resize(img, IMG_SIZE)
            img = img.astype(np.float32) / 255.0
            yield img, label
        else:
            print(f"Failed to load image: {path}")

def create_dataset(paths, labels, batch_size):
    dataset = tf.data.Dataset.from_generator(
        lambda: image_generator(paths, labels),
        output_signature=(
            tf.TensorSpec(shape= (64, 64, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(), dtype=tf.int32)
        )
    )
    dataset = dataset.repeat().shuffle(len(paths)).batch(batch_size)
    return dataset

train_dataset = create_dataset(X_train, y_train, BATCH_SIZE)
valid_dataset = create_dataset(X_valid, y_valid, BATCH_SIZE)

"""---

# Creating the model
"""

from tensorflow.keras.models import Model
from tensorflow.keras import layers

base_model = keras.applications.VGG16(
    include_top=False,
    weights='imagenet',
    pooling='max')

base_model.trainable = False

"""## Adding some augmentation"""

augmentor = keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.1)
])

classes = len(np.unique(label_mapping))

input = layers.Input(shape = (64, 64, 3))
x = augmentor(input)
x = base_model(x)
x = layers.Dense(100, activation ='silu')(x)
x = layers.Dropout(0.25)(x)
output = layers.Dense(classes, activation='softmax')(x)

model = Model(input, output)

model.summary()

lr = keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate = 0.01,
    first_decay_steps = 100) # variable lr to avoid getting stuck during training

loss = keras.losses.SparseCategoricalCrossentropy()

callback = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)

model.compile(
    optimizer = keras.optimizers.AdamW(lr),
    loss = loss,
    metrics = ['accuracy']
)

steps_per_epoch = max(1, len(X_train) // BATCH_SIZE)
validation_steps = max(1, len(X_valid) // BATCH_SIZE)

"""---

# Training

We used only 10 epochs due to the free Colab's limitation. But we can see from this cell output that the early stopping would act 'cause our validation loss wasn't decreasing anymore. Therefore, only 10 epochs wasn't so harmful.
"""

# check the output. We can see that there is some fail when loading the image 39403... since its only this one giving us some headaches, we will procceed as nothing happened.

history = model.fit(train_dataset,
                    validation_data = valid_dataset,
                    batch_size = 32,
                    epochs = 10,
                    steps_per_epoch=steps_per_epoch,
                    validation_steps=validation_steps,
                    callbacks=[callback])

"""## Saving and downloading the products

Since it took a long time to get to this point, we left some coding to download the results in case Colab kicks you out. Uncomment id needed.
"""

# # Uncomment if needed

# from keras import saving
# model.save('/content/rec_model.keras')

# # Uncomment if needed

# from keras import saving
# from keras.saving import load_model
# model = load_model('/content/rec_model.keras')

"""---

# Defining our feature extractor
"""

extractor_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)

# # Uncomment if needed

# from keras import saving
# model.save('/content/extract_model.keras')

"""## Checking output

The following cell works as a checkpoint. We used it to check if everything is working so far. The example used was arbitrary.
"""

IMG_SIZE = (64, 64)

example = '/content/myntradataset/images/10000.jpg'

def pred_preprocess(path):
  img = cv2.imread(path)
  new_input = None

  if img is not None:
    img = cv2.resize(img, IMG_SIZE)
    img = img.astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=0)
    new_input = tf.convert_to_tensor(img)
  else:
    print(f"Failed to load image: {path}")

  return new_input

inee = pred_preprocess(example)

pred = extractor_model.predict(inee)

"""Seems fine

---

# Extracting features

Now, we will use our extractor to obtain 100 features that represent each product and add them to the csv. It will be our "dataset of features" to be compared with the features of the new products later.
"""

probabilities = []

for filename in data_train['id']:
    image = pred_preprocess(filename)

    if image is not None:
      pred = extractor_model.predict(image, verbose=0)
      probabilities.append(pred)

    else:
      probabilities.append(np.zeros(100))

data_train['Probabilities'] = probabilities

"""This "39403.jpg" is still here... lets keep going

## Saving the csv

Since the previous cell took a long time to finish its execution, we added another saving point here. Uncomment if needed.
"""

# # Uncomment if needed

# data_train.to_csv('/content/Full_data.csv', index=False)

# # Uncomment if needed

# from google.colab import files
# files.download('/content/Full_data.csv')

"""---

# Recommendation function

Ok! Now we have our extractor working and our "features dataset" (some kind od embedding). The next step is to define a function that uses the product selected by the costumer (for example) and recommend 3 more based only on the bigger correlation between the features of that product and our "features dataset". Four images are exibited at the end: the original product and three similars.
"""

import matplotlib.pyplot as plt

info = ['gender', 'masterCategory',	'subCategory',	'articleType',	'productDisplayName']

def find_and_display_3_closest_items(path_new_item):
    """
    "path_new_item" must be an image.

    This function returns the 3 closest items considering only the correlation between the features.
    """

    image = pred_preprocess(path_new_item)

    if image is None:
        print("Failed to load image.")
        return None

    matrix1 = extractor_model.predict(image, verbose=1)

    def matrix_correlation(matrix2):
      return np.corrcoef(matrix1.flatten(), matrix2.flatten())[0, 1]

    data_train['Distance'] = data_train['Probabilities'].apply(lambda x: matrix_correlation(np.array(x)))
    correlations = data_train.sort_values(by='Distance', ascending=False)

    closest_items = correlations.iloc[:3]

    # display images
    fig, axes = plt.subplots(1, 4, figsize=(15, 5))

    original_image = cv2.imread(path_new_item)
    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    axes[0].imshow(original_image)
    axes[0].set_title("Original")
    axes[0].axis("off")

    for i, (_, row) in enumerate(closest_items.iterrows()):
        image_path = row['id']
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        axes[i + 1].imshow(img)
        axes[i + 1].set_title(f"Similar {i+1}")
        axes[i + 1].axis("off")

    plt.show()

    return closest_items[info]

"""---

# Lets work on our examples
"""

examples = data.iloc[rmv_indexes]
examples

examples['id'] = '/content/myntradataset/images/' + examples['id'] + '.jpg'

"""## Example 1"""

item = examples['id'].iloc[0]

find_and_display_3_closest_items(item)

"""## Example 2"""

item = examples['id'].iloc[1]

find_and_display_3_closest_items(item)

"""## Example 3"""

item = examples['id'].iloc[2]

find_and_display_3_closest_items(item)

"""## Example 4"""

item = examples['id'].iloc[3]

find_and_display_3_closest_items(item)

"""---

# Comments

Since our goals was to perform recommendation based only on feature extraction (DioMe instructions for this activity) we did not use the metadata from the csv as parameters (gender, productDisplayName, articleType and stuff). This could have improved some recommendations and avoid some (in my opinion) mismatches like casual with formal shoes, purses with watches and even nail polishers with perfumes.

Using more features (filters in the Dense layer) could improve the recommendations (the cited notebook used 256 and here we used 100) since more parameters would be available. The usage of the full dataset could also bring some improvementes, but we must have in mind that we have a huge unbalance.

Instead of correlation between the feature matrices, some other metrics as euclidean distance could have been used here. A PCA could also been performed.
"""